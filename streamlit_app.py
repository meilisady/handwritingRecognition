# -*- coding: utf-8 -*-
"""streamlitApp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L4cyGxkK3_OC8ztA_hOjzTyatNTgYeSr
"""



import streamlit as st
import numpy as np
import cv2
import os
from keras.models import load_model
from PIL import Image
import string
from utils.center_align import add_padding
from utils.image_straighten import deskew, unshear
from utils.segmentation import lineSegment, wordSegment, fitToSize, findCapPoints, baselines, histogram, visualize, segmentCharacters

# Set page config
st.set_page_config(page_title="Handwritten Letter Recognition", layout="centered")

# Load model
@st.cache_resource
def load_model_once():
    return load_model("model/Mnist1L_5Conv.h5")

model = load_model_once()
letter_map = {v: k for k, v in dict(zip(string.ascii_lowercase, range(1, 27))).items()}

st.title("üìù Handwritten Letter Recognition")

uploaded_file = st.file_uploader("Upload a handwritten letter image", type=["png", "jpg", "jpeg"])

if uploaded_file:
    # Load image
    file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
    image = cv2.imdecode(file_bytes, cv2.IMREAD_GRAYSCALE)

    st.subheader("Original Image")
    st.image(image, use_column_width=True, clamp=True)

    # Preprocessing
    thresh = cv2.threshold(image, 127, 255, 1)[1]
    thresh = np.pad(thresh, 100, mode='constant', constant_values=0)
    de_skewed = deskew(thresh)
    sheared = unshear(de_skewed)
    ret, processed = cv2.threshold(sheared, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

    try:
        textLines = lineSegment(cv2.cvtColor(processed, cv2.COLOR_GRAY2BGR))
        wordImgs = wordSegment(textLines)

        st.subheader("Segmented Characters and Predictions")

         predicted_sentence = ""

        for img in wordImgs:
            predicted_word = ""  # Accumulate characters for one word

            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            th, letterGray = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
            letterGray = fitToSize(letterGray)
            letterGray = cv2.dilate(letterGray, None, iterations=4)

            h, w = letterGray.shape
            upoints, dpoints = findCapPoints(letterGray)
            meanu, lb = baselines(img.copy(), upoints, dpoints)
            colcnt = histogram(img.copy(), meanu, lb)

            seg = visualize(img.copy(), meanu, lb, 25, 35, 190)
            charImgs = segmentCharacters(seg, letterGray)

            for char_img in charImgs:
                char_img = cv2.resize(char_img, (20, 20))
                padded_img = add_padding(char_img, 4, 4, 4, 4)
                padded_img = padded_img / 255.0
                padded_img = padded_img.reshape(-1, 28, 28, 1)

                prediction = model.predict(padded_img)
                predicted_class = np.argmax(prediction, axis=1)[0]
                predicted_letter = letter_map.get(predicted_class, '?')

                predicted_word += predicted_letter

                # Optional: show each char and its prediction
                col1, col2 = st.columns([1, 2])
                with col1:
                    st.image(char_img, clamp=True)
                with col2:
                    st.markdown(f"### üß† Prediction: `{predicted_letter}`")

            predicted_sentence += predicted_word + " "  # Add space between words

        # Final sentence output
        st.subheader("üìú Predicted Sentence")
        st.markdown(f"## ‚úèÔ∏è `{predicted_sentence.strip()}`")
    except Exception as e:
        st.error(f"Failed to segment or recognize: {e}")